# segment.bytes of Kafka's Topics
`segment.bytes` เป็นการตั้งค่าที่สำคัญใน Kafka topic ซึ่งมีผลต่อการจัดการและประสิทธิภาพของ topic ดังนี้:

1. ความหมาย:
   - `segment.bytes` กำหนดขนาดสูงสุดของแต่ละ segment file ใน Kafka

2. ผลกระทบต่อ Topic:

   a) การจัดการไฟล์:
      - Kafka แบ่งข้อมูลใน topic ออกเป็น segments
      - เมื่อ segment ปัจจุบันเต็ม (ถึงขนาดที่กำหนด) Kafka จะสร้าง segment ใหม่
      - ช่วยในการจัดการไฟล์ข้อมูลขนาดใหญ่

   b) ประสิทธิภาพ:
      - Segments ขนาดใหญ่อาจเพิ่มประสิทธิภาพการเขียนแต่อาจลดประสิทธิภาพการอ่าน
      - Segments ขนาดเล็กอาจเพิ่มประสิทธิภาพการอ่านแต่อาจเพิ่มภาระในการจัดการไฟล์

   c) การทำ Log Retention:
      - เมื่อ Kafka ต้องลบข้อมูลเก่า (ตาม retention policy) จะลบทีละ segment
      - ขนาด segment ที่ใหญ่อาจทำให้ข้อมูลถูกเก็บไว้นานกว่าที่กำหนดใน retention.ms

   d) การกู้คืนข้อมูล:
      - หาก broker ล้มเหลว การกู้คืนข้อมูลจะทำทีละ segment
      - Segments ขนาดใหญ่อาจใช้เวลาในการกู้คืนนานขึ้น

   e) ประสิทธิภาพการใช้ disk I/O:
      - Segments ขนาดใหญ่อาจช่วยลด disk I/O operations
      - แต่อาจเพิ่มเวลาในการ seek หาข้อมูลเฉพาะ

3. การพิจารณา ค่าตัวอย่าง segment.bytes=943718400 (900 MB):
   - เหมาะสำหรับ topics ที่มีปริมาณข้อมูลสูงและต้องการประสิทธิภาพการเขียนที่ดี
   - อาจไม่เหมาะกับ topics ที่ต้องการ retention ที่แม่นยำมาก
   - อาจทำให้การกู้คืนข้อมูลใช้เวลานานหากเกิดปัญหา

4. คำแนะนำ:
   - พิจารณาปรับค่านี้ตามลักษณะการใช้งานของ topic
   - สำหรับ topics ที่มีข้อมูลขนาดเล็กแต่จำนวนมาก อาจพิจารณาลดขนาด segment
   - สำหรับ topics ที่ต้องการ retention ที่แม่นยำ อาจพิจารณาลดขนาด segment
   - ติดตามประสิทธิภาพและพฤติกรรมของ topic หลังจากการตั้งค่านี้

- หากต้องการปรับค่า `segment.bytes` สามารถใช้คำสั่ง `kafka-configs` 
---
การพิจารณาขนาด segment ที่เหมาะสมขึ้นอยู่กับหลายปัจจัย โดยเฉพาะลักษณะของข้อมูลและความต้องการในการใช้งาน สำหรับกรณี (Avg message size 250 bytes และ 8 TPS) วิเคราะห์และคำนวณ:

1. คำนวณปริมาณข้อมูลต่อวัน:
   * ข้อมูลต่อวินาที = 250 bytes * 8 TPS = 2,000 bytes/second
   * ข้อมูลต่อวัน = 2,000 * 60 * 60 * 24 = 172,800,000 bytes/day ≈ 165 MB/day

2. พิจารณา Retention:
   * หากต้องการ retention 7 วัน, ข้อมูลทั้งหมดจะประมาณ 165 MB * 7 ≈ 1.16 GB

3. พิจารณาขนาด Segment:
   * ทั่วไปแล้ว ควรตั้งค่า segment.bytes ให้เล็กกว่าขนาดข้อมูลทั้งหมดที่ต้องการเก็บ
   * ควรพิจารณาให้ segment มีขนาดที่ทำให้สามารถลบข้อมูลได้ใกล้เคียงกับ retention.ms ที่ต้องการ

4. คำนวณขนาด Segment ที่เหมาะสม:
   * เพื่อให้สามารถลบข้อมูลได้ใกล้เคียงรายวัน, อาจพิจารณาตั้ง segment.bytes ประมาณ 1-2 เท่าของข้อมูลต่อวัน
   * ในกรณีนี้, อาจตั้ง segment.bytes ประมาณ 165-330 MB

5. ข้อพิจารณาเพิ่มเติม:
   * ถ้าต้องการ retention ที่แม่นยำมาก อาจลดขนาด segment ลงอีก เช่น ครึ่งวันหรือ 1/4 ของวัน
   * ถ้าคำนึงถึงประสิทธิภาพการเขียนมากกว่า อาจเพิ่มขนาด segment ให้ใหญ่ขึ้น

คำแนะนำ:
ในกรณีนี้, แนะนำให้ตั้งค่า `segment.bytes` ประมาณ 200-250 MB ซึ่งจะทำให้:
- สามารถลบข้อมูลได้ค่อนข้างแม่นยำตาม retention policy
- มี segments จำนวนพอเหมาะ ไม่มากหรือน้อยเกินไป
- ใช้ทรัพยากรในการจัดการ segments อย่างมีประสิทธิภาพ

>ตัวอย่างคำสั่งในการปรับ segment.bytes:

```bash
.\bin\kafka-configs.sh --bootstrap-server kafka.abc.xxx:9092 \
--alter \
--entity-type topics \
--entity-name test1 \
--add-config segment.bytes=262144000 \
--command-config admin-client.properties
```
คำสั่งนี้จะตั้งค่า `segment.bytes` เป็น 250 MB (262,144,000 bytes)

>และตัวอย่างคำสั่งตรวจสอบค่า Topic

```bash
kafka-topics --describe --topic test1 \
--bootstrap-server kafka.abc.xxx:9092 \
--command-config admin-client.properties
```

---

### อธิบายการคำนวณและเหตุผล:

1. ข้อมูลพื้นฐาน:
   - ข้อมูลต่อวัน = 165 MB

2. การพิจารณา:
   a) ถ้าต้องการ retention ที่แม่นยำมาก:
      - อาจใช้ขนาด segment เท่ากับข้อมูลครึ่งวัน: 165 MB / 2 ≈ 82.5 MB
      - หรือ 1/4 ของวัน: 165 MB / 4 ≈ 41.25 MB

   b) ถ้าคำนึงถึงประสิทธิภาพการเขียน:
      - อาจใช้ขนาด segment เท่ากับข้อมูล 1-2 วัน: 165-330 MB

3. การสมดุล:
   - เราต้องการสมดุลระหว่างความแม่นยำของ retention และประสิทธิภาพการเขียน
   - ขนาด 250 MB เป็นค่าที่อยู่ระหว่างกลางของทั้งสองแนวทาง

4. เหตุผลในการเลือก 250 MB:
   - ใหญ่กว่าข้อมูล 1 วัน เล็กน้อย (165 MB) เพื่อรองรับความผันผวนของปริมาณข้อมูล
   - เล็กกว่าข้อมูล 2 วัน (330 MB) เพื่อให้สามารถลบข้อมูลได้ค่อนข้างแม่นยำ
   - เป็นตัวเลขกลมที่ง่ายต่อการจดจำและจัดการ

5. การปรับแต่งเพิ่มเติม:
   - หากพบว่า retention ไม่แม่นยำพอ อาจลดลงเป็น 200 MB หรือ 165 MB
   - หากพบว่าประสิทธิภาพการเขียนไม่ดีพอ อาจเพิ่มเป็น 300 MB หรือ 330 MB

สรุป:
การแนะนำ 250 MB เป็นจุดเริ่มต้นที่สมเหตุสมผล โดยพิจารณาจากปริมาณข้อมูลต่อวันและพยายามสมดุลระหว่างความแม่นยำของ retention กับประสิทธิภาพการเขียน อย่างไรก็ตาม การตั้งค่าที่เหมาะสมที่สุดอาจต้องมีการทดสอบและปรับแต่งในสภาพแวดล้อมจริง

---

>>การปรับ segment.bytes สำหรับการใช้งานจริง :



ข้อมูลปัจจุบัน:
1. retention.ms = 157680000000 (ประมาณ 5 ปี)
2. retention.bytes = 536870912000 (500 GB)
3. partition count = 16
4. segment.bytes = 1073741824 (1 GB)

การใช้งานจริง:
- avg message size = 200 bytes
- TPS (Transactions Per Second) = 6

การวิเคราะห์:

1. ปริมาณข้อมูลต่อวัน:
   6 TPS * 200 bytes * 86400 seconds = 103,680,000 bytes/วัน ≈ 98.88 MB/วัน

2. ปริมาณข้อมูลต่อ partition ต่อวัน:
   98.88 MB / 16 partitions ≈ 6.18 MB/partition/วัน

3. เวลาในการเติมเต็ม 1 segment (1 GB):
   1 GB / 6.18 MB ≈ 162 วัน

4. จำนวน segments ทั้งหมดที่สามารถเก็บได้ตาม retention.bytes:
   500 GB / 1 GB = 500 segments

5. ระยะเวลาที่สามารถเก็บข้อมูลได้ตาม retention.bytes:
   500 segments * 162 วัน ≈ 81,000 วัน หรือประมาณ 222 ปี

ความเห็นและคำแนะนำ:

1. segment.bytes ปัจจุบัน (1 GB) ดูเหมาะสมแล้ว เนื่องจาก:
   - ใช้เวลานานพอสมควร (162 วัน) ในการเติมเต็ม 1 segment
   - ไม่ทำให้เกิด segments จำนวนมากเกินไป

2. retention.bytes (500 GB) เพียงพอสำหรับการเก็บข้อมูลนานกว่า retention.ms (5 ปี) ที่กำหนดไว้

3. หากต้องการปรับ segment.bytes ควรพิจารณา:
   - ลดลงเล็กน้อย เช่น 512 MB หากต้องการให้ segments หมุนเวียนเร็วขึ้น
   - เพิ่มขึ้น เช่น 2 GB หากต้องการลดจำนวน segments และการจัดการไฟล์

4. ไม่จำเป็นต้องปรับ segment.bytes เพื่อให้สอดคล้องกับ retention.ms และ retention.bytes เนื่องจากค่าปัจจุบันไม่ขัดแย้งกัน

สรุป: ค่า segment.bytes ปัจจุบันมีความเหมาะสมแล้ว แต่หากต้องการปรับแต่งเพิ่มเติม สามารถพิจารณาตามคำแนะนำข้างต้นได้ ทั้งนี้ขึ้นอยู่กับความต้องการเฉพาะของระบบและทรัพยากรที่มี

